{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 54, 54]          11,712\n",
      "            Conv2d-2          [-1, 256, 26, 26]         614,656\n",
      "            Conv2d-3          [-1, 384, 12, 12]         885,120\n",
      "            Conv2d-4          [-1, 384, 12, 12]       1,327,488\n",
      "            Conv2d-5          [-1, 256, 12, 12]         884,992\n",
      "            Linear-6                 [-1, 4096]      26,218,496\n",
      "            Linear-7                 [-1, 4096]      16,781,312\n",
      "            Linear-8                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 46,764,746\n",
      "Trainable params: 46,764,746\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 4.64\n",
      "Params size (MB): 178.39\n",
      "Estimated Total Size (MB): 183.23\n",
      "----------------------------------------------------------------\n",
      "torch.Size([256, 1, 224, 224])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "nll_loss_nd(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [25], line 67\u001B[0m\n\u001B[0;32m     65\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     66\u001B[0m pred_y \u001B[38;5;241m=\u001B[39m net(train_x)\n\u001B[1;32m---> 67\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrain_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10000\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss:\u001B[39m\u001B[38;5;132;01m{:.4f}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(loss))\n",
      "File \u001B[1;32mD:\\miniconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:2701\u001B[0m, in \u001B[0;36mnll_loss\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001B[0m\n\u001B[0;32m   2699\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2700\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 2701\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnll_loss_nd\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: nll_loss_nd(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean=[0.5,],std=[0.5,])])\n",
    "\n",
    "data_train = datasets.FashionMNIST(root=\"./data\",\n",
    "                                   transform=transform,\n",
    "                                   train=True,\n",
    "                                   download=True)\n",
    "data_test = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    transform=transform,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
    "                                                batch_size=256,\n",
    "                                                shuffle=True)\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
    "                                               batch_size=256,\n",
    "                                               shuffle=True)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,96,kernel_size=11,stride=4,padding=1)\n",
    "        self.conv2 = nn.Conv2d(96,256,kernel_size=5,padding=2)\n",
    "        self.conv3 = nn.Conv2d(256,384,kernel_size=3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(384,384,kernel_size=3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(384,256,kernel_size=3,padding=1)\n",
    "        self.fc1 = nn.Linear(6400,4096)\n",
    "        self.fc2 = nn.Linear(4096,4096)\n",
    "        self.fc3 = nn.Linear(4096,10)\n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),3,2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),3,2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.max_pool2d(x,3,2)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x,0.5)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x,0.5)\n",
    "        x = F.relu(self.fc3(x))\n",
    "net = Net()\n",
    "summary(net,(1,224,224))\n",
    "lr = 0.5\n",
    "num_epochs = 10\n",
    "criterion = F.nll_loss\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for idx,(train_x,train_label) in enumerate(data_loader_train):\n",
    "        optimizer.zero_grad()\n",
    "        pred_y = net(train_x)\n",
    "        loss = criterion(pred_y,train_label)\n",
    "        if idx % 10000 == 0:\n",
    "            print(\"loss:{:.4f}\".format(loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    all_correct_num = 0\n",
    "    all_sample_num = 0\n",
    "    net.eval()\n",
    "    for i, (test_x,test_label) in enumerate(data_loader_test):\n",
    "        pred_y = net(test_x.float()).detach()\n",
    "        pred_y = np.argmax(pred_y,axis=-1)\n",
    "        current_correct_num = pred_y == test_label\n",
    "        all_correct_num += np.sum(current_correct_num.numpy(),axis=-1)\n",
    "        all_sample_num += current_correct_num.shape[0]\n",
    "    acc = all_correct_num / all_sample_num\n",
    "    print(\"epoch {:d}: acc = {:.4f}\".format(epoch,acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
